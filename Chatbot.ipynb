{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TryXaZEjN6hg"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJLXCa4qmiGM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain qdrant_client openai tiktoken"
      ],
      "metadata": {
        "id": "0lnwvWlDmrH6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba1e3cb4-009a-42f3-8251-1dc48b4e4948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.340-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qdrant_client\n",
            "  Downloading qdrant_client-1.6.9-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.2/182.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.3.5-py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.8/220.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.2-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Downloading langsmith-0.0.66-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (1.59.2)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant_client)\n",
            "  Downloading grpcio_tools-1.59.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx[http2]>=0.14.0 (from qdrant_client)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker<3.0.0,>=2.7.0 (from qdrant_client)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Collecting urllib3<2.0.0,>=1.26.14 (from qdrant_client)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting protobuf<5.0dev,>=4.21.6 (from grpcio-tools>=1.41.0->qdrant_client)\n",
            "  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio>=1.41.0 (from qdrant_client)\n",
            "  Downloading grpcio-1.59.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant_client) (67.7.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.14.0->qdrant_client) (2023.7.22)\n",
            "Collecting httpcore==1.* (from httpx[http2]>=0.14.0->qdrant_client)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx[http2]>=0.14.0->qdrant_client)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2<5,>=3 (from httpx[http2]>=0.14.0->qdrant_client)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant_client)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant_client)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: urllib3, protobuf, portalocker, mypy-extensions, marshmallow, jsonpointer, hyperframe, hpack, h11, grpcio, typing-inspect, jsonpatch, httpcore, h2, grpcio-tools, tiktoken, langsmith, httpx, dataclasses-json, openai, langchain, qdrant_client\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.59.2\n",
            "    Uninstalling grpcio-1.59.2:\n",
            "      Successfully uninstalled grpcio-1.59.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.2 grpcio-1.59.3 grpcio-tools-1.59.3 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.2 httpx-0.25.2 hyperframe-6.0.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.340 langsmith-0.0.66 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-1.3.5 portalocker-2.8.2 protobuf-4.25.1 qdrant_client-1.6.9 tiktoken-0.5.1 typing-inspect-0.9.0 urllib3-1.26.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install PyPDF2"
      ],
      "metadata": {
        "id": "3nMExiIhy5xZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5f9cf02-0992-406e-b416-0bc772aaa296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/232.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install sentence-transformers"
      ],
      "metadata": {
        "id": "x_oFWt3dAsin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.vectorstores import Qdrant\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from qdrant_client.http.models import PointStruct\n",
        "from qdrant_client import QdrantClient,models\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Qdrant\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain, RetrievalQA\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
        "from langchain.callbacks import get_openai_callback\n",
        "from langchain.vectorstores import DeepLake\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.chains import LLMChain\n",
        "import PyPDF2\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "import glob\n",
        "import time\n",
        "import qdrant_client\n",
        "import os\n",
        "import uuid\n",
        "import openai"
      ],
      "metadata": {
        "id": "_HRQcxNTnevN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a qdrant_client\n",
        "\n",
        "# qdrant Token\n",
        "\n",
        "client = qdrant_client.QdrantClient(\n",
        "    os.getenv(\"QDRANT_HOST\"),\n",
        "    api_key=os.getenv(\"QDRANT_API_KEY\"),\n",
        ")"
      ],
      "metadata": {
        "id": "SbKLwA-2nyot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create collection\n",
        "\n",
        "os.environ['QDRANT_COLLECTION_NAME'] = \"my-collections-test\" #cambia esto acorde a tu base de datos de vectores(si ya tienes no es necesario crear un lector de pdf)\n",
        "                                                            # Change this according to your vector database (if you already have one, there is no need to create a PDF reader)\n",
        "vectors_config = qdrant_client.http.models.VectorParams(\n",
        "    size=1536,\n",
        "    distance=qdrant_client.http.models.Distance.COSINE\n",
        ")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=os.getenv(\"QDRANT_COLLECTION_NAME\"),\n",
        "    vectors_config=vectors_config,\n",
        ")\n"
      ],
      "metadata": {
        "id": "01X02dIEpI9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector store.\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = \"PUT YOUR TOKEN HERE\"\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "# knowlegde_base = QdrantClient.text\n",
        "\n",
        "vector_store = Qdrant(\n",
        "    client=client,\n",
        "    collection_name=os.getenv(\"QDRANT_COLLECTION_NAME\"),\n",
        "    embeddings=embeddings,\n",
        ")\n"
      ],
      "metadata": {
        "id": "2CHROiL5tgQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knowledge_base = Chroma.from_documents(chunks, embeddings, persist_directory = persist_directory)\n",
        "new_knowledge_base = Qdrant(persist_directory = persist_directory, embedding_function = embeddings)"
      ],
      "metadata": {
        "id": "ri1x_wakLV-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add document to vector store.  Esto es para leer el pdf, pasarlo a chunks y meterlo en los vector store\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap = 100,\n",
        "    length_function = len\n",
        ")\n",
        "\n",
        "pdf_file_obj = open('habitos-atomicos-james-clear.pdf', 'rb')\n",
        "pdf_reader = PdfReader(pdf_file_obj)\n",
        "\n",
        "text = \"\"\n",
        "for page in pdf_reader.pages:\n",
        "    text += page.extract_text()\n",
        "\n",
        "chunks = text_splitter.split_text(text)\n",
        "\n",
        "'''\n",
        "texts = get_chunks(pdf_reader)\n",
        "'''\n",
        "\n",
        "vector_store.add_texts(chunks)\n"
      ],
      "metadata": {
        "id": "yV0N8CiJv8lL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c313602-fbaf-4716-bc50-21525dc19890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['d71379a5977d4ae3ae3ae5fc29bc3d94']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knowledge_base = Qdrant.from_documents(chunks, embeddings, persist_directory = persist_directory)\n",
        "\n",
        "knowledge_base.persist()\n",
        "\n",
        "new_knowledge_base = Qdrant(persist_directory = persist_directory, embedding_function = embeddings)"
      ],
      "metadata": {
        "id": "K9hAICoML7fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieval chain. Esto es para llamar. Si ya tienes una base de datos con los vectores no es necesario crear una funcion que lea, sencillamente recarga\n",
        "# Lo que quiero es meter esto osea la variable qa dentro de un texto\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=ChatOpenAI(temperature = 0,\n",
        "                   model_name='gpt-3.5-turbo', callbacks=[StreamingStdOutCallbackHandler()], streaming = True,)\n",
        "    #retriever=vector_store.as_retriever()\n",
        ")"
      ],
      "metadata": {
        "id": "uSuPmrtSAQRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test de la base de datos vectorial\n",
        "# Test of Vectorial DB\n",
        "\n",
        "query = \"Como hago un buen habito?\"\n",
        "\n",
        "response = qa.run(query)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "7zS7Vf3pE9D2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sl_SDNi-FG9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain\n",
        "from langchain.llms import OpenAI # no uso (don't need it)\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "pcor0cRjQBf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test final"
      ],
      "metadata": {
        "id": "djt60-mxNFLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"habitos-atomicos-james-clear.pdf\"\n",
        "\n",
        "def print_letter_by_letter(text):\n",
        "    for char in text:\n",
        "        print(char, end='', flush=True)\n",
        "        time.sleep(0.02)"
      ],
      "metadata": {
        "id": "IjwpB-YLNIPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test fail"
      ],
      "metadata": {
        "id": "TryXaZEjN6hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n"
      ],
      "metadata": {
        "id": "TeqpeciVmXPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for making texto into chunks\n",
        "\n",
        "def get_text_chunks(text):\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "dYtZT16ws7H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chunks to embeddings\n",
        "\n",
        "def get_embedding(text_chunks, model_id=\"text-embedding-ada-002\"):\n",
        "    points = []\n",
        "    for idx, chunk in enumerate(text_chunks):\n",
        "        response = openai.Embedding.create(\n",
        "            input=chunk,\n",
        "            model=model_id\n",
        "        )\n",
        "        embeddings = response['data'][0]['embeddings']\n",
        "        point_id = str(uuid.uuid4()) #esto es para generar un id unico para cada chunk\n",
        "        points.append(PointStruct(id=point_id, vector=embeddings, payload={\"text\": chunk}))\n",
        "        return points"
      ],
      "metadata": {
        "id": "eyJ79lZWuBGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para meter los datos en Qdrant\n",
        "\n",
        "def insert_data(get_points):\n",
        "    operation_info = connection.upsert(\n",
        "    collection_name=\"my-collections-test\",\n",
        "    wait = True,\n",
        "    points=get_points\n",
        ")"
      ],
      "metadata": {
        "id": "dNAveKtFyQwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creando la pregunta con el contexto\n",
        "def create_answer_with_context(query):\n",
        "    response = openai.Embedding.create(\n",
        "        input=query,\n",
        "\n",
        "        model=\"text-embedding-ada-002\"\n",
        "    )\n",
        "    embeddings = response['data'][0]['embeddings']\n",
        "\n",
        "    search_result= connection.search(\n",
        "        collection_name=\"my-collections-test\",\n",
        "        query_vector=embeddings,\n",
        "        limit=1\n",
        "    )\n",
        "    prompt = \"Context:\\n\"\n",
        "    for result in search_result:\n",
        "        prompt += result.payload['text'] + \"\\n---\\n\"\n",
        "    prompt += \"Question\" + query + \"\\n---\\n\" + \"Answer:\"\n",
        "\n",
        "    print(\"---- PROMPT START ----\")\n",
        "    print(\":\", prompt)\n",
        "    print(\"---- PROMPT END ----\")\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model = \"gpt-3.5-turbo\",\n",
        "        messages =[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return completion.choice[0].messege.content"
      ],
      "metadata": {
        "id": "ZQApxr_00kSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    get_raw_text= read_data_from_pdf()\n",
        "    chunks= get_text_chunks(get_raw_text)\n",
        "    vectors= get_embedding(chunks)\n",
        "\n",
        "    insert_data(vectors)\n",
        "    question=\"Dime como crear buenos habitos\"\n",
        "    answer=create_answer_with_context(question)\n",
        "    print(answer)"
      ],
      "metadata": {
        "id": "LDAMCnSd4KKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "H3_oVyMg58ET",
        "outputId": "2603a471-c41f-4a78-b0cb-51e7abd378d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c7bc734e5e35>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-58f8e84378e6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mget_raw_text\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mread_data_from_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mchunks\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mget_text_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_raw_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvectors\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'read_data_from_pdf' is not defined"
          ]
        }
      ]
    }
  ]
}